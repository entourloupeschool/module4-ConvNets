{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Warning : \n",
        "# Do \"File -> Save a copy in Drive\" before you start modifying the notebook, otherwise your modifications will not be saved."
      ],
      "metadata": {
        "id": "WhgR65jog--N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0) Loading MNIST data"
      ],
      "metadata": {
        "id": "WgO2_8dqmNpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "zjUX9Lu4iCkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_Yp95xEhb_G"
      },
      "outputs": [],
      "source": [
        "# Load MNIST dataset\n",
        "bsize = 100\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,),(0.3081,))])\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=bsize, shuffle=True)#, **kwargs)\n",
        "test_loader = DataLoader(test_dataset, batch_size=bsize)#, **kwargs)\n",
        "\n",
        "# Visualize some images\n",
        "images, labels = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "fig, axes = plt.subplots(nrows=4, ncols=4)\n",
        "for i, (image, label) in enumerate(zip(images, labels)):\n",
        "    if i >= 16:\n",
        "        break\n",
        "    axes[i // 4][i % 4].imshow(images[i][0], cmap='gray')\n",
        "    axes[i // 4][i % 4].set_title(f\"{label}\")\n",
        "    axes[i // 4][i % 4].set_xticks([])\n",
        "    axes[i // 4][i % 4].set_yticks([])\n",
        "fig.set_size_inches(8, 8)\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) Classification Models"
      ],
      "metadata": {
        "id": "P8reklBgmXAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.A) Let us define a Logistic regression model"
      ],
      "metadata": {
        "id": "adrAgQF0mlRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LR(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LR, self).__init__()\n",
        "    # YOUR CODE\n",
        "\n",
        "  def forward(self, x):\n",
        "    # YOUR CODE"
      ],
      "metadata": {
        "id": "W_KtY6VXk5RD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LR().to(device)\n",
        "print(lr)\n",
        "\n",
        "pred = lr(images.to(device))\n",
        "print(pred.shape)"
      ],
      "metadata": {
        "id": "zxBemQmjnof8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train the LR model!"
      ],
      "metadata": {
        "id": "D40jE0GapI_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(lr.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepochs = 10\n",
        "\n",
        "for e in range(nbepochs):\n",
        "  total_loss, correct = 0.0, 0.0\n",
        "  for (images, labels) in train_loader: \n",
        "    # ZERO GRAD\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    im, lab = images.to(device), labels.to(device)\n",
        "    # FORWARD : YOUR CODE\n",
        "    #pred = \n",
        "    # LOSS COMPUTATION : YOUR CODE\n",
        "    #loss = \n",
        "    total_loss += loss\n",
        "    correct += (pred.argmax(-1) == lab).sum()\n",
        "    \n",
        "    # BACKWARD + GRADIENT STEP : YOUR CODE\n",
        "\n",
        "\n",
        "  print(f\"[Epoch {e + 1:2d}] loss: {total_loss/ len(train_dataset):.2E} accuracy_train: {correct / len(train_dataset):.2%}\")\n"
      ],
      "metadata": {
        "id": "D9S6EneQpMK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evalTest(testloader, net):\n",
        "  total_loss, nbSamples, correct=0.0, 0.0, 0.0\n",
        "\n",
        "  for (images, labels) in testloader: \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    im, lab = images.to(device), labels.to(device)\n",
        "    pred = net(im)\n",
        "\n",
        "    loss = criterion(pred, lab)\n",
        "    total_loss += loss\n",
        "    correct += (pred.argmax(-1) == lab).sum()\n",
        "    nbSamples += images.shape[0]\n",
        "\n",
        "  acc = correct / nbSamples*100.0\n",
        "  return acc, total_loss / nbSamples"
      ],
      "metadata": {
        "id": "HOkvWh8Rsubi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accT= evalTest(test_loader, lr)[0]\n",
        "print(f\"Test accuracy={accT:.2f}%\")"
      ],
      "metadata": {
        "id": "aF-I3YRTtN2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.B) Let's now define a MLP with a single hidden layer of size 100"
      ],
      "metadata": {
        "id": "DulEPF0Aurrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleMLP, self).__init__()\n",
        "    # YOUR CODE\n",
        "\n",
        "  def forward(self, x):\n",
        "    # YOUR CODE\n"
      ],
      "metadata": {
        "id": "kMkVaa5RuyW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train the MLP model!"
      ],
      "metadata": {
        "id": "oak42XQx1V6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepochs = 20\n",
        "\n",
        "for e in range(nbepochs):\n",
        "  total_loss, correct = 0.0, 0.0\n",
        "  for (images, labels) in train_loader: \n",
        "    # BATCH LOOP: YOUR CODE \n"
      ],
      "metadata": {
        "id": "vgMuKc-51PB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accT= evalTest(test_loader, mlp)[0]\n",
        "print(f\"Test accuracy={accT:.2f}%\")"
      ],
      "metadata": {
        "id": "JCnFM4nFuHSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.C) Let's now define a ConvNet with a two [Conv + Pool] layers and one hidden layer: \n",
        "\n",
        "\n",
        "1.   Conv1: 16 filters of size 5x5, no padding ('valid)'\n",
        "  - ReLU\n",
        "  - Pool1: MaxPool2d, stride 2\n",
        "2.   Conv2: 32 filters of size 5x5, no padding \n",
        "  - ReLU\n",
        "  - Pool1: MaxPool2d, stride 2\n",
        "3. One fully connected layer of size 100 (flatteing before applying it)\n",
        "3. One fully connected layer of size 10 (number of classes)\n"
      ],
      "metadata": {
        "id": "gKari8Lr6JIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(LeNet, self).__init__()\n",
        "      # self.conv1 = \n",
        "      # self.maxpool1 = \n",
        "      # self.conv2 = \n",
        "      # self.maxpool2 = \n",
        "      # self.fc1 = \n",
        "      # self.fc2 = \n",
        "\n",
        "    def forward(self, x):\n",
        "      # YOUR CODE\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "VI_uQlU23LjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ],
      "metadata": {
        "id": "h_TNxCEY_QLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenet = LeNet().to(device)\n",
        "print(lenet)\n",
        "\n",
        "npar = count_parameters(lenet)\n",
        "print(f\"number of parameters in lenet ={npar :d}\")"
      ],
      "metadata": {
        "id": "A3qwNpt38oI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets train the ConvNet!"
      ],
      "metadata": {
        "id": "m6cqf5fO_1DP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_testoptimizer = torch.optim.SGD(lenet.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "nbepochs = 20\n",
        "# TRAINING LOOP: YOUR CODE \n",
        "\n"
      ],
      "metadata": {
        "id": "wnCHc9Ux_8q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accT= evalTest(test_loader, lenet)[0]\n",
        "print(f\"Test accuracy={accT:.2f}%\")"
      ],
      "metadata": {
        "id": "IIcsfXx-Aqzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) Manifold untangling"
      ],
      "metadata": {
        "id": "MgxajUTvGC-4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's get the full test data "
      ],
      "metadata": {
        "id": "faH_zyo1GGMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "X_test = np.zeros((10000,784))\n",
        "Y_test = np.zeros((10000,))\n",
        "\n",
        "bsize=100\n",
        "\n",
        "for id, (images, labels) in enumerate(test_loader): \n",
        "    X_test[id*bsize:id*bsize+bsize,:] = images.view(-1,784)\n",
        "    Y_test[id*bsize:id*bsize+bsize] = labels"
      ],
      "metadata": {
        "id": "Ka8yyPioGJfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.A) t-SNE on raw data"
      ],
      "metadata": {
        "id": "OCTJDm5qnOE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "from scipy.spatial import ConvexHull\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from scipy import linalg\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# TSNE: creation + call fit_transform to get the 2D projection X_r\n",
        "#tsne = \n",
        "#X_r = "
      ],
      "metadata": {
        "id": "DP8aILpHJbQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_ellipses(points, labels):\n",
        "  # computing best fiiting ellipse for a set of points with asscoiated labels\n",
        "  gaussians = []\n",
        "  for i in range(10):\n",
        "    gaussians.append(GaussianMixture(n_components=1, covariance_type='full').fit(points[labels==i, :]))\n",
        "  return gaussians\n",
        "\n",
        "def neighboring_hit(points, labels):\n",
        "  k = 6\n",
        "  nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(points)\n",
        "  distances, indices = nbrs.kneighbors(points)\n",
        "\n",
        "  txs = 0.0\n",
        "  txsc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "  nppts = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "  for i in range(len(points)):\n",
        "    tx = 0.0\n",
        "    for j in range(1,k+1):\n",
        "      if (labels[indices[i,j]]== labels[i]):\n",
        "        tx += 1\n",
        "    tx /= k\n",
        "    txsc[int(labels[i])] += tx\n",
        "    nppts[int(labels[i])] += 1\n",
        "    txs += tx\n",
        "\n",
        "  for i in range(10):\n",
        "    txsc[i] /= nppts[i]\n",
        "\n",
        "  return txs / len(points)"
      ],
      "metadata": {
        "id": "gXLGPN3VK78x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing best fitting ellipses\n",
        "ellipses = best_ellipses(X_r, labelsT)\n",
        "# computing nh\n",
        "nh = neighboring_hit(X_r, labelsT)"
      ],
      "metadata": {
        "id": "5JaVlNgiK_VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualization(points2D, labels, ellipses, nh):\n",
        "    points2D_c= []\n",
        "    for i in range(10):\n",
        "        points2D_c.append(points2D[labels==i, :])\n",
        "    # Data Visualization\n",
        "    cmap =cm.tab10\n",
        "    \n",
        "    plt.figure(figsize=(8, 4), dpi=200)\n",
        "    plt.set_cmap(cmap)\n",
        "    plt.subplots_adjust(hspace=0.4 )\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(points2D[:,0], points2D[:,1], c=labels,  s=3,edgecolors='none', cmap=cmap, alpha=1.0)\n",
        "    plt.colorbar(ticks=range(10))\n",
        "    plt.title(\"2D t-SNE - NH=\"+str(nh*100.0))\n",
        "    \n",
        "    vals = [ i/10.0 for i in range(10)]\n",
        "    \n",
        "    def plot_results(X, Y_, means, covariances, index, title, color):\n",
        "        splot = plt.subplot(1, 2, 2)\n",
        "        for i, (mean, covar) in enumerate(zip(means, covariances)):\n",
        "            v, w = linalg.eigh(covar)\n",
        "            v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
        "            u = w[0] / linalg.norm(w[0])\n",
        "            # as the DP will not use every component it has access to\n",
        "            # unless it needs it, we shouldn't plot the redundant\n",
        "            # components.\n",
        "            if not np.any(Y_ == i):\n",
        "              continue\n",
        "            plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color, alpha = 0.2)\n",
        "\n",
        "            # Plot an ellipse to show the Gaussian component\n",
        "            angle = np.arctan(u[1] / u[0])\n",
        "            angle = 180. * angle / np.pi  # convert to degrees\n",
        "            ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
        "            ell.set_clip_box(splot.bbox)\n",
        "            ell.set_alpha(0.6)\n",
        "            splot.add_artist(ell)\n",
        "\n",
        "        plt.title(title)\n",
        "\n",
        "    for i in range(10):\n",
        "        plot_results(points2D[labels==i, :], ellipses[i].predict(points2D[labels==i, :]), ellipses[i].means_, ellipses[i].covariances_, 0,\"t-SNE fitting ellipses\", cmap(vals[i]))\n",
        "\n",
        "    #plt.savefig(projname+\".png\", dpi=100)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "zjYj4TCnLFJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "visualization(X_r, labelsT, ellipses, nh)"
      ],
      "metadata": {
        "id": "IhBIk4OOLIBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUESTION:** what wan you conclude from the t-SNE visualization?"
      ],
      "metadata": {
        "id": "5eLIFSvcnUi-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.B) t-SNE on latent space from MLP"
      ],
      "metadata": {
        "id": "epqnWOuIniad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The code below enables to extract a latent vector instead of the output prediction, as follows"
      ],
      "metadata": {
        "id": "ugmr5qYagTZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activation = {}\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activation[name] = output.detach()\n",
        "    return hook"
      ],
      "metadata": {
        "id": "rP1hxE1bNXtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp.fc1.register_forward_hook(get_activation('fc1'))\n",
        "\n",
        "H_test_MLP = np.zeros((10000,100))\n",
        "\n",
        "bsize=100\n",
        "\n",
        "for id, (images, labels) in enumerate(test_loader): \n",
        "    output = mlp(images.to(device))\n",
        "    H_test_MLP[id*bsize:id*bsize+bsize,:] = activation['fc1'].cpu().numpy()"
      ],
      "metadata": {
        "id": "V1Bb1AujlXVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute t-SNE on H_test_MLP\n",
        "# H_r="
      ],
      "metadata": {
        "id": "B8JC3wGKlgwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing best fitting ellipses\n",
        "ellipses = best_ellipses(H_r2, labelsT)\n",
        "# computing nh\n",
        "nh = neighboring_hit(H_r2, labelsT)\n",
        "# t-SNE visualization\n",
        "visualization(H_r2, labelsT, ellipses , nh)"
      ],
      "metadata": {
        "id": "iyqWvwxZlltm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.C) t-SNE on latent space from ConvNet"
      ],
      "metadata": {
        "id": "-53NuNU9oC4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the same for the ConvNet\n",
        "# Latent 'fc1' feature extraction\n",
        "# TSNE\n",
        "# Visualization"
      ],
      "metadata": {
        "id": "JZyDbXvkN6NS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}